\documentclass{article}
\usepackage{mathpazo}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[a4paper,left=2cm,right=4cm,top=2cm,bottom=2cm]{geometry}
\usepackage{setspace}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{graphicx}

\usepackage{xspace,amsmath}
\newcommand{\um}{\ensuremath{\mu \text{m}}\xspace}
\usepackage{url}
\usepackage[authoryear]{natbib}
\newcommand{\dynamic}{(Dynamic)}
\newcommand{\static}{(Static)}
\newcommand{\hdfgroup}[1]{\texttt{#1}}

\begin{document}
\bibliographystyle{plain}
\onehalfspacing
\title{Machine Learning Methods Applied to Micro-Electrode Array Data }

\author{Diana Hall, M.S. Statistics }
\author{Institute of Genomic Medicine, Columbia University, New York, NY, USA }
\date{\today}

\maketitle

% * is used to remove the default numbering of sections
\section*{Abstract}
We want to understand which features, or combination thereof, are the most reliable across WT. Simiarly, we seek to understand which set of features is most reliable different in a single strain. A strain is a breeding mouse line, some of which have a mutation of interest others of which are considered wild type.  The data is interrogated to answer the following questions. 
\begin{itemize}
\item Which combination of 3 features are the most?
\item how well can be wt vs mutant be classified?
\end{itemize}

\section{ Introduction }
Microelectrode array (MEA) recordings are a useful tool to study the activity of networks of interconnected neurons, both in vitro and in vivo. In vitro, neural networks on MEAs demonstrate many characteristics of intact neural networks; this includes extracellular recordings of action potentials (“spikes”) and groups of action potentials (“bursts”) simultaneously from multiple points in the network.1 The spontaneous activity in these networks exhibits pharmacological responsiveness and plasticity. Thus, primary cultures of neural networks on MEAs have been widely utilized to study neurophysiology, neuropharmacology, and neurotoxicology REFERNCE NEEDED(for review, see Johnstone et). 

While the data used in this study is not new, the unique contribution made by this approach to analysis will be in discovering which combination of features extracted from MEA recordings have the least variance culture to culture. Additionally, the analysis method will uncover which featuer combination are most different between the mutant and wild-type.  Previously, MEA data has been tracked over time for differences in individual features. There are been relatively little work on combinations of features.


\section*{Data}
The data was collected on a micro-electrode array (MEA) REFERENCE TO MEA. The data was collected by by Chris Bostick, Ph.D. at the Institute of Genomic Medicine at Columbia University. The strain Black 6 NJ mice. They were bred so that some would be heterozygous for a mutation in the KCNT1 gene. The data has been recorded and prepared only by Chris Bostick, so it's unlikely to contain multiple A total of 72 MEA wells of cultured coritical neurons recorded over 3 different days, across 3 different plates (DIV) will be used. 36 of these wells contain are comprised of neuronal cultures from wild-type mice, while the remaining 36 wells contain cultures from mice homozygous for a mutation in KCNT1. Each well is comprised of data from 16 individual electrodes that collected spike times, to the mili-second, from neurons that overlay them in the culture. Each electrode spike times can be organized to extract various features from the spikes times that include aspects of rate, clumping, synchronozation across electrodes within one well and organization.  The features used will be nAE (no active electrodes), mFR (mean firing rate), mISI (mean Inter-Spike interval), sdISI (st dev of Inter-Spike interval), mDB (mean duration of bursts), bpm (burst per minute), cvIBI (coefficient of variation for inter burst interval), mFB (mean frequency in burst), sdFB (st dev frequency in burst), mSPB (mean spikes per burst), mIBI (mean inter burst interval), pm (peak mean), mNBT (mean network burst time), SPB (spikes per burst), pSIB (percent spikes in bursts), and number of bursts.

\section{Preliminary Methods}

What analyses have you performed already to convince yourself that your project is feasible?


\section{Proposed Methods}
What are you proposing to do to answer the question (or address the challenge) that you pose in your abstract and introduction? Be specific about the new data sources you will integrate, or the methods that you will use. For example, if you are proposing to do factor analysis then are you going to use PCA or ICA? Explain your choice. If you are going to use machine learning, then which method? Are you doing regression analysis or classification? 


\section{Evaluation Strategy}
This may be the most important part of your proposal. Once you run the analysis you propose in the section above, how will you evaluate the results? Will you use cross-validation, hold-out validation? Or will you try to replicate your analysis in a completely new dataset? What is your gold standard? These decisions will largely be driven by the available data and knowledge for the specific biomedical domain you are studying. For example, if you are attempting to find novel genes for a disease, then you could evaluate your method by trying to predict which genes already are known to be involved in the disease. If you are trying to find new drugs for an indication, then you can evaluate by trying to predict known drugs. What statistical methods will you use in this evaluation?

\section{Preliminary Results}
Describe what you found from running your preliminary analysis. Describe the figures and tables that you generated. Do not interpret the results in this section, simply report on the facts.

\section{Discussion}

The discussion section should have three subsections: summary, anticipated results, and conclusions.

\section{Summary}
Recap the general problem you are tyring to solve and the method you are poposing to solve it. Interpret your preliminary results. Do the preliminary results support your analysis? Do they identify potential pitfalls or limitations?

\section{Anticipated Results}
Describe what you expect to see from running your proposed methods. Describe how you will interpret the results if they conform to what you expect. Describe how you will interpret the results if they do not conform to what you expect. Describe the assumptions you’re your analysis is based on and where the analysis could fail. What can you do if that happens?

\section{Conclusion}
Provide 1-2 sentences summarizing the proposal’s goals and potential impact. 



<<setup, include=FALSE, cache=FALSE, echo=F>>=
library(knitr)
# set global chunk options
opts_chunk$set(fig.path='figure/minimal-', fig.align='center', fig.show='hold')
options(replace.assign=TRUE,width=90)
@
  
  
<<install-github,eval=FALSE,echo=F,include=TRUE>>=


# attach packages to current session
require(meaRtools)
library(xtable)
library(parallel)
require(meadq)
library(tree)
library(randomForest)
library(gbm)
library(e1071)
library(modeest)
library(FactoMineR)
@ 
  

<<directories and filenames,eval=T,echo=F,include=FALSE>>=

#source(paste(root.dir,"HistoricOntogenyAnalysis/Analysis/classification_functions/classification_functions.R",sep=""))
# analyse DIV25, DIV27, and DIV29 to start
#num.cores<-1 #changed from 4
data.dir<-"/Users/dh2744/Dropbox/Columbia/Software/github/WT_analysis/PCA_KCNT1_Data"
list.data.dirs<-list.dirs(data.dir)
dirs.want<-list.data.dirs[ grep("outputPerDIV", list.data.dirs ) ]
for (i in 1:length(dirs.want) ){
  # i=1
  cur.files<-list.files(dirs.want[i], full.names = T)
  which.want<-as.vector( sapply(c("DIV25", "DIV27", "DIV29"),  grep , cur.files ) )
  files.want<-cur.files[which.want]
  files.want<-files.want [grep("csv", files.want ) ]
  
  
}

# read in and make big thing out of files
i=1
data.ns<-c()
data.burst<-c()
data.spikes<-c()
for (i in 1:length(files.want)){
  cur.file<-files.want[i]
  if( grepl( "DIV25",cur.file) ){
    cur.div<-25
  } else if ( grepl( "DIV27",cur.file) ){
    cur.div<-27
  } else if (grepl( "DIV29",cur.file)) {
    cur.div<-29
  }
  
  if (  grepl("spikes", cur.file )  ){
    t.spikes<-read.csv(files.want[i], skip=3, header=T, nrows=48)
    t.spikes<-cbind.data.frame(DIV=rep(cur.div, dim(t.spikes)[1] ), t.spikes )
    data.spikes<-rbind.data.frame(data.spikes, t.spikes  )
    
  } else if( grepl("bursts", cur.file ) ) {
    t.bursts<-read.csv(files.want[i], skip=5, header=T, nrows=48 )
    t.bursts<-cbind.data.frame(DIV=rep(cur.div, dim(t.bursts)[1] ), t.bursts )
    data.burst<-rbind.data.frame(data.burst, t.bursts  )
    
  } else if (grepl("ns", cur.file )){
    t.ns<-read.csv(files.want[i], skip=5, header=T, nrows=48 )
    t.ns<-cbind.data.frame(DIV=rep(cur.div, dim(t.ns )[1] ), t.ns )
    data.ns<-rbind.data.frame(data.ns, t.ns  )
    
  }
  
}

colnames(data.spikes)[2]<-"well"


# nAE (no active electrodes), 
# mFR (mean firing rate), 
# mISI (mean Inter-Spike interval), 
# sdISI (st dev of Inter-Spike interval), 
# mDB (mean duration of bursts), 
# bpm (burst per minute), 
# cvIBI (coefficient of variation for inter burst interval), 
# mFB (mean frequency in burst), 
# sdFB (st dev frequency in burst), 
# mSPB (mean spikes per burst), 
# mIBI (mean inter burst interval), 
# pm (peak mean), 
# mNBT (mean network burst time), 
# SPB (spikes per burst), 
#pSIB (percent spikes in bursts), and 
# number of bursts.

cols.want.ns<-c("DIV",   "peak.m","percent.of.spikes.in.ns", "well", "mean.insis","treatment")
cols.want.burst<-c("DIV", "treatment","well","mean.freq.in.burst","cv.IBIs","sd.ISIs", "mean.ISIs", 
                   "mean.dur", "bursts.per.min", "sd.freq.in.burst", "mean.IBIs", "per.spikes.in.burst")
cols.want.spikes<-c("DIV","treatment","well", "nAE", "meanfiringrate_by_active_electordes")

all.cols<-union( union(cols.want.ns, cols.want.burst), cols.want.spikes  )

data.ns.1<-data.ns[, is.element( colnames(data.ns),cols.want.ns ) ]
data.burst.1<-data.burst[, is.element( colnames(data.burst),cols.want.burst ) ]
data.spikes.1<-data.spikes[, is.element( colnames(data.spikes),cols.want.spikes ) ]

all.data<-cbind.data.frame(data.burst.1, data.ns.1, data.spikes.1 )
all.data<-all.data[,all.cols]

#subet the data
all.data<-all.data[ is.element(all.data$treatment, c("WT","HOM")),  ]




@   
  
\section*{PCA of WT Only}
<<pca1, eval=T, echo=F, include=T >>=
# first only with WT
all.data.wt<-all.data[ is.element(all.data$treatment, c("WT")),  ]

#
quali.sup.vars<-which( is.element( colnames(all.data.wt), c( "treatment", "well") ) )
div.col<-which( colnames(all.data.wt)=="DIV") 
all.data.wt<-all.data.wt[,-quali.sup.vars]

col<-rep("blue", length(all.data$treatment))


res1<-PCA( all.data.wt, quali=div.col,  graph=F)
plot( res1, choix="ind", label="none",
      habillage=1  ,invisible="quali" )




@


<<pca12, eval=T, echo=F, include=T >>=

#DIV, 
quali.sup.vars<-c(1,4,6)
all.data<-all.data[,-c(1,4)]

col<-rep("blue", length(all.data$treatment))
col[ grepl( "HOM", all.data$treatment ) ]="red"

res1<-PCA( all.data, quali=4,  graph=F)
plot( res1, choix="ind", label="none",
      habillage=4  ,invisible="quali" )
#plot( res1, choix="ind", label="none", habillage="ind"  ,invisible="quali" , col.hab = col )

num.features=5
combo3<-t( combn( setdiff(1:ncol(all.data.quant),quali.sup.vars) , 
                 num.features, FUN = NULL, simplify = TRUE) )

for ( i in 1:nrow(combo3) ){
  cur.data<-all.data[,c( combo3[i, ], 4) ]
  res1<-PCA( cur.data, quali=4,  graph=F)
  plot( res1, choix="ind", label="none",
      habillage=4  ,invisible="quali" )

}





@





\end{document}
